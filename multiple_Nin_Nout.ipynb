{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64635ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import importlib\n",
    "\n",
    "from typing import Tuple, List\n",
    "from numpy import array, zeros\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# from Big_Class import Big_Class  # already imported one NETfuncs is imported\n",
    "from User_Variables import User_Variables  # already imported one NETfuncs is imported\n",
    "from Network_Structure import Network_Structure  # already imported one NETfuncs is imported\n",
    "from Big_Class import Big_Class\n",
    "from Network_State import Network_State\n",
    "from Networkx_Net import Networkx_Net\n",
    "import matrix_functions, functions, statistics, plot_functions, solve, figure_plots, colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e289950",
   "metadata": {},
   "source": [
    "## colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed404fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAGnRFWHRUaXRsZQBjdXN0b21fY21hcCBjb2xvcm1hcOa9R1QAAAAgdEVYdERlc2NyaXB0aW9uAGN1c3RvbV9jbWFwIGNvbG9ybWFwd6MDAgAAADB0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuOS4yLCBodHRwczovL21hdHBsb3RsaWIub3JnYZnFUwAAADJ0RVh0U29mdHdhcmUATWF0cGxvdGxpYiB2My45LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmdPP1p0AAABj0lEQVR4nO3WW0rDUBRA0VPH6LAdhCNp/VGEW0ofxBjYa/2kvSH3EVrYp/ePz8vMzJxnZmZOl+X6z+NzsP2s4zff21H3dZDxeXWe+Pvb+v/wM9/y9fd66/73h/M6fu+5B+e999zT6260n6t1//icT6/76n6W+5ud88n97n3Odfy80zmvzrvT72i9vg0AkCMAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAR9AYUII7ONq3z/AAAAAElFTkSuQmCC\n",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>custom_cmap</strong> </div><div class=\"cmap\"><img alt=\"custom_cmap colormap\" title=\"custom_cmap\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAGnRFWHRUaXRsZQBjdXN0b21fY21hcCBjb2xvcm1hcOa9R1QAAAAgdEVYdERlc2NyaXB0aW9uAGN1c3RvbV9jbWFwIGNvbG9ybWFwd6MDAgAAADB0RVh0QXV0aG9yAE1hdHBsb3RsaWIgdjMuOS4yLCBodHRwczovL21hdHBsb3RsaWIub3JnYZnFUwAAADJ0RVh0U29mdHdhcmUATWF0cGxvdGxpYiB2My45LjIsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmdPP1p0AAABj0lEQVR4nO3WW0rDUBRA0VPH6LAdhCNp/VGEW0ofxBjYa/2kvSH3EVrYp/ePz8vMzJxnZmZOl+X6z+NzsP2s4zff21H3dZDxeXWe+Pvb+v/wM9/y9fd66/73h/M6fu+5B+e999zT6260n6t1//icT6/76n6W+5ud88n97n3Odfy80zmvzrvT72i9vg0AkCMAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAQJAAAIEgAAECQAACBIAABAkAAAgCABAABBAgAAggQAAAR9AYUII7ONq3z/AAAAAElFTkSuQmCC\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#54cce0ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #54cce0ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#4500e0ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #4500e0ff;\"></div></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.LinearSegmentedColormap at 0x20a064dfa00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_lst, red, cmap = colors.color_scheme()\n",
    "cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662c4c88",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a33df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters\n",
    "\n",
    "## task type\n",
    "task_type='Regression'\n",
    "\n",
    "\n",
    "# ## task matrix X\n",
    "# M_values: np.ndarray = array([0.15, 0.2, 0.015, 0.1, 0.01, 0.03, 0.05, 0.12, 0.23, 0.25, 0.12, 0.1, 0.02, 0.3, 0.35, 0.25,\n",
    "#                               0.03, 0.02, 0.25, 0.31, 0.02, 0.08, 0.35, 0.1, 0.03, 0.2, 0.1, 0.18, 0.12, 0.35, 0.05, 0.15,\n",
    "#                               0.25, 0.25, 0.02, 0.01, 0.08, 0.07, 0.35, 0.15, 0.01, 0.25, 0.13, 0.05, 0.03, 0.3, 0.32, 0.05,\n",
    "#                               0.15, 0.12, 0.25, 0.1, 0.25, 0.3, 0.25, 0.25, 0.04, 0.27, 0.1, 0.11, 0.02, 0.2, 0.4, 0.15,\n",
    "#                               ])\n",
    "\n",
    "## specify # of nodes\n",
    "Nin: int = 0\n",
    "extraNin: int = 0\n",
    "Ninter: int = 0\n",
    "Nout: int = 0\n",
    "extraNout: int = 0\n",
    "\n",
    "# resistance-pressure proportionality factor\n",
    "gamma: np.ndarray = np.array([1.0])\n",
    "\n",
    "## method to update resistances - physical property of the system\n",
    "R_update: str = 'R_propto_dp'\n",
    "# R_update: str = 'deltaR_propto_dp'\n",
    "# R_update: str = 'deltaR_propto_Q'\n",
    "# R_update: str = 'deltaR_propto_Power'\n",
    "R_vec_i = array([1.])\n",
    "\n",
    "alpha: float = 0.1  # for network combine attempt\n",
    "stay_sample: int = 2\n",
    "\n",
    "# length of training dataset\n",
    "iterations = int(2e4)  # number of sampled of p\n",
    "\n",
    "stay_sample = 2\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# measure accuracy every # steps\n",
    "measure_accuracy_every = 15\n",
    "\n",
    "supress_prints: bool = True  # whether to print information during training or not\n",
    "bc_noise: float = 0.0  # noise to dual problem\n",
    "use_p_tag: bool = False  # use 1 or 2 sampled pressures at every time step\n",
    "include_Power: bool = False\n",
    "lam: float = 0\n",
    "    \n",
    "access_interNodes: bool = False  # access and change pressure at interNodes (nodes between input and output) or not\n",
    "noise_to_extra: bool = False  # add noise to extra outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ade198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_build_given_Nin_Nout(Nin: int, Nout: int, M_values: NDArray[np.float_]) -> tuple():\n",
    "    \n",
    "    # initialize Variables\n",
    "    Variabs = User_Variables(iterations,\\\n",
    "                             Nin, \\\n",
    "                             extraNin, \\\n",
    "                             Ninter, \\\n",
    "                             Nout, \\\n",
    "                             extraNout, \\\n",
    "                             gamma, \\\n",
    "                             R_update, \\\n",
    "                             use_p_tag, \\\n",
    "                             include_Power, lam, \\\n",
    "                             supress_prints, \\\n",
    "                             bc_noise, \\\n",
    "                             access_interNodes, \\\n",
    "                             task_type, \\\n",
    "                             measure_accuracy_every)\n",
    "    \n",
    "    Variabs.assign_alpha_vec(alpha)\n",
    "    \n",
    "    # Normalize M\n",
    "    # M_values_norm = normalize([M_values[:Nin*Nout]], norm=\"l1\")[0]/2  # normalize Nin*Nout values of M to norm of 0.5\n",
    "    M_mat = M_values[0:Nout*Nin].reshape(Nout, Nin)\n",
    "    M_line = np.sum(M_mat, axis=1)\n",
    "    M_values_norm = M_values[:Nin*Nout]/np.max(M_line)*0.75  # normalize so max sum over line will be 0.75\n",
    "    # M_values_norm = copy.copy(M_values[:Nin*Nout])  # don't normalize\n",
    "    print('M_norm', M_values_norm)\n",
    "    Variabs.create_dataset_and_targets(random_state, M_values_norm)\n",
    "    Variabs.create_noise_for_extras()\n",
    "    BigClass = Big_Class(Variabs)\n",
    "        \n",
    "    # initialize Structure\n",
    "    inInterOutGround_tuple = matrix_functions.build_input_output_and_ground(Variabs.Nin, Variabs.extraNin, Variabs.Ninter, \n",
    "                                                                            Variabs.Nout, Variabs.extraNout)\n",
    "        \n",
    "    \n",
    "    Strctr = Network_Structure(inInterOutGround_tuple)\n",
    "    Strctr.build_incidence()\n",
    "    Strctr.build_edges()\n",
    "    BigClass.add_Strctr(Strctr)  # add to big class\n",
    "    \n",
    "    # initialize State    \n",
    "    State = Network_State(Variabs)\n",
    "    State.initiate_resistances(BigClass, R_vec_i)\n",
    "    State.initiate_accuracy_vec(BigClass, measure_accuracy_every)\n",
    "    BigClass.add_State(State)  # add to big class\n",
    "    \n",
    "    return Variabs, Strctr, State, BigClass\n",
    "\n",
    "\n",
    "def random_gen_M(random_state: int, size: NDArray[np.int_]) -> NDArray[np.float_]:\n",
    "    \"\"\"\n",
    "    random_gen_M generates a random M_values array for regression task\n",
    "    use for multiple_Nin_Nout for example, and before train_loop()\n",
    "    \n",
    "    inputs:\n",
    "    random_state - int, random seed\n",
    "    size         - size of M_values, train_loop then decides how many to take\n",
    "    \"\"\"\n",
    "    # generate random state\n",
    "    random_gen = np.random.RandomState(random_state)\n",
    "\n",
    "    # Generate random values with the defined random state\n",
    "    M_values = random_gen.rand(size)\n",
    "    \n",
    "    return M_values\n",
    "\n",
    "\n",
    "def train_loop(Variabs, Strctr, State, BigClass):\n",
    "    loss_mean = [1, 1]\n",
    "    for l in range(Variabs.iterations):\n",
    "        \n",
    "        k = (l//stay_sample)*2 + l%2\n",
    "\n",
    "        # draw input and desired outputs from dataset\n",
    "        if not((l+1) % 4):  # add noise only at i=3 etc.\n",
    "            State.draw_p_in_and_desired(Variabs, k, noise_to_extra=False)  # add noise to extra nodes every 2nd iteration\n",
    "            State.solve_flow_given_problem(BigClass, \"measure\", noise_to_extra=False)  # measure and don't change resistances\n",
    "        else:  # dont add noise to extra nodes\n",
    "            State.draw_p_in_and_desired(Variabs, k)\n",
    "            State.solve_flow_given_problem(BigClass, \"measure\")\n",
    "\n",
    "        if not l % 2:  # even iterations, take another sampled pressure and measure again\n",
    "            pass\n",
    "        else:  # odd iterations, go to dual problem and update resistances\n",
    "            State.t += 1\n",
    "            State.calc_loss(BigClass)\n",
    "            State.update_input_dual(BigClass)\n",
    "            State.update_output_dual(BigClass)\n",
    "            State.solve_flow_given_problem(BigClass, \"dual\", access_inters=False)  # measure and don't change resistances\n",
    "            State.update_Rs(BigClass)\n",
    "            \n",
    "        if not (l+1)%window_for_mean:\n",
    "            # print('l', l)\n",
    "            loss_mean.append(np.mean(np.mean(np.abs(State.loss_in_t[-window_for_mean:]), axis=1)))\n",
    "            # print(loss_mean)\n",
    "            \n",
    "#         if loss_mean[-1]<10e-8 or (loss_mean[-1]-loss_mean[-2])>0 or loss_mean[-1]>2:\n",
    "#             break\n",
    "            \n",
    "    return State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcae6f",
   "metadata": {},
   "source": [
    "# Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b4c43e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# window_for_mean = 1000\n",
    "# n = 10\n",
    "# random_state_M_vec = array([42, 43, 44, 45, 46, 47, 48, 49]) \n",
    "# norm_mean_loss = np.zeros([n,n, np.shape(random_state_M_vec)[0]])\n",
    "\n",
    "# for k, random_state_M in enumerate(random_state_M_vec):\n",
    "#     M_values = random_gen_M(random_state_M, n*n)\n",
    "#     for i in range(n):\n",
    "#         for j in range(n):\n",
    "#             Nin: int = i + 1\n",
    "#             Nout: int = j + 1\n",
    "#             print('Nin', Nin)\n",
    "#             print('Nout', Nout)\n",
    "\n",
    "#             Variabs, Strctr, State, BigClass = network_build_given_Nin_Nout(Nin, Nout, M_values)\n",
    "#             State = train_loop(Variabs, Strctr, State, BigClass)\n",
    "\n",
    "#             norm_mean_loss_ij = np.mean(np.mean(np.abs(State.loss_norm_in_t[-window_for_mean:]), axis=1))\n",
    "#             # norm_mean_loss_ij = mean_loss_ij / np.mean(Variabs.targets)\n",
    "#             print('norm_mean_loss_ij', norm_mean_loss_ij)\n",
    "\n",
    "#             norm_mean_loss[i, j, k] = norm_mean_loss_ij\n",
    "#             # plot_functions.plot_importants(State, Variabs, State.desired_in_t, Variabs.M, include_network=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f088b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration out of 8:  0\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  0\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.29546741 0.75      ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.392969451991563e-16\n",
      "iteration out of 8:  0\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.29546741 0.75       0.57745576]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.0285786032692966e-16\n",
      "iteration out of 8:  0\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.29546741 0.75       0.57745576 0.47227002]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.258939697131918e-16\n",
      "iteration out of 8:  0\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.29546741 0.75       0.57745576 0.47227002 0.12308007]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.8716379665886426e-16\n",
      "iteration out of 8:  0\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.21196314 0.53803686]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.397887673610567e-17\n",
      "iteration out of 8:  0\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10393331354606739\n",
      "iteration out of 8:  0\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385 0.0879373  0.0879237 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09536650241168676\n",
      "iteration out of 8:  0\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385 0.0879373  0.0879237\n",
      " 0.03273786 0.48820571]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.9999998273352526\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385 0.0879373  0.0879237\n",
      " 0.03273786 0.48820571]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1377094710623743\n",
      "iteration out of 8:  0\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385 0.0879373  0.0879237\n",
      " 0.03273786 0.48820571 0.33880843 0.39909327]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.498836487105663\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.21110328 0.53585423 0.41257615 0.33742385 0.0879373  0.0879237\n",
      " 0.03273786 0.48820571 0.33880843 0.39909327]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12449039840643004\n",
      "iteration out of 8:  0\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.13654408 0.34659681 0.2668591 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.069775477542235e-17\n",
      "iteration out of 8:  0\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.13654408 0.34659681 0.2668591  0.21824971 0.05687888 0.05687009]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13333834903923816\n",
      "iteration out of 8:  0\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.13654408 0.34659681 0.2668591  0.21824971 0.05687888 0.05687009\n",
      " 0.02117523 0.31577719 0.21914527]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11330765122808348\n",
      "iteration out of 8:  0\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.13654408 0.34659681 0.2668591  0.21824971 0.05687888 0.05687009\n",
      " 0.02117523 0.31577719 0.21914527 0.25813822 0.00750438 0.35359483]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.17001249968738336\n",
      "iteration out of 8:  0\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.13654408 0.34659681 0.2668591  0.21824971 0.05687888 0.05687009\n",
      " 0.02117523 0.31577719 0.21914527 0.25813822 0.00750438 0.35359483\n",
      " 0.30347915 0.07741133 0.06628695]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.5856831604887924\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.13654408 0.34659681 0.2668591  0.21824971 0.05687888 0.05687009\n",
      " 0.02117523 0.31577719 0.21914527 0.25813822 0.00750438 0.35359483\n",
      " 0.30347915 0.07741133 0.06628695]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.18593349900559136\n",
      "iteration out of 8:  0\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.348408434811275e-16\n",
      "iteration out of 8:  0\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.707032560464287\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.14177095685118632\n",
      "iteration out of 8:  0\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898 0.16974852 0.19995221 0.00581284 0.27389228]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.7269141296673907\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898 0.16974852 0.19995221 0.00581284 0.27389228]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12655127937550334\n",
      "iteration out of 8:  0\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898 0.16974852 0.19995221 0.00581284 0.27389228\n",
      " 0.235073   0.05996232 0.05134545 0.05179149]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.9974271324192571\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898 0.16974852 0.19995221 0.00581284 0.27389228\n",
      " 0.235073   0.05996232 0.05134545 0.05179149]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1440181492493819\n",
      "iteration out of 8:  0\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.10576617 0.26847166 0.20670735 0.16905482 0.04405801 0.0440512\n",
      " 0.0164022  0.24459898 0.16974852 0.19995221 0.00581284 0.27389228\n",
      " 0.235073   0.05996232 0.05134545 0.05179149 0.08591479 0.14818567\n",
      " 0.1219767  0.08224003]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1358709296413564\n",
      "iteration out of 8:  0\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.0260901820958374e-05\n",
      "iteration out of 8:  0\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347 0.04160704\n",
      " 0.01549213 0.2310275  0.16033009 0.18885793]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10760522333141997\n",
      "iteration out of 8:  0\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347 0.04160704\n",
      " 0.01549213 0.2310275  0.16033009 0.18885793 0.00549032 0.25869547\n",
      " 0.22203006 0.05663533 0.04849656]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.4514169028338958\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347 0.04160704\n",
      " 0.01549213 0.2310275  0.16033009 0.18885793 0.00549032 0.25869547\n",
      " 0.22203006 0.05663533 0.04849656]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1132557697386594\n",
      "iteration out of 8:  0\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347 0.04160704\n",
      " 0.01549213 0.2310275  0.16033009 0.18885793 0.00549032 0.25869547\n",
      " 0.22203006 0.05663533 0.04849656 0.04891786 0.08114784 0.13996364\n",
      " 0.11520887 0.07767697]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10258001505148244\n",
      "iteration out of 8:  0\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.09989777 0.25357561 0.19523827 0.15967488 0.04161347 0.04160704\n",
      " 0.01549213 0.2310275  0.16033009 0.18885793 0.00549032 0.25869547\n",
      " 0.22203006 0.05663533 0.04849656 0.04891786 0.08114784 0.13996364\n",
      " 0.11520887 0.07767697 0.16319411 0.03720596 0.07792116 0.09771645\n",
      " 0.12164351]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11131963460445095\n",
      "iteration out of 8:  1\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  1\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.14167734 0.75      ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.7718137130486868e-16\n",
      "iteration out of 8:  1\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.14167734 0.75       0.16425664]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 6.123403290259878e-16\n",
      "iteration out of 8:  1\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.14167734 0.75       0.16425664 0.29626027]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 3.4104497193369506e-16\n",
      "iteration out of 8:  1\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.14167734 0.75       0.16425664 0.29626027 0.4028366 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.7890343037997436e-16\n",
      "iteration out of 8:  1\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.11916643 0.63083357]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.0393355184729554e-16\n",
      "iteration out of 8:  1\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.11916643 0.63083357 0.13815814 0.2491879 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.036533970902776644\n",
      "iteration out of 8:  1\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.07274099 0.38507033 0.08433381 0.15210805 0.20682723 0.54317277]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07564337603629498\n",
      "iteration out of 8:  1\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.07147712 0.37837978 0.08286852 0.14946519 0.20323363 0.5337352\n",
      " 0.41380547 0.33619453]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.1765517562801344\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.07147712 0.37837978 0.08286852 0.14946519 0.20323363 0.5337352\n",
      " 0.41380547 0.33619453]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11995221313331506\n",
      "iteration out of 8:  1\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.07147712 0.37837978 0.08286852 0.14946519 0.20323363 0.5337352\n",
      " 0.41380547 0.33619453 0.0180247  0.45583774]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.6839621691739133\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.07147712 0.37837978 0.08286852 0.14946519 0.20323363 0.5337352\n",
      " 0.41380547 0.33619453 0.0180247  0.45583774]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.14293559818882928\n",
      "iteration out of 8:  1\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.1006294  0.53270376 0.11666684]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.3609137011401362e-16\n",
      "iteration out of 8:  1\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.06047584 0.32014208 0.07011395 0.1264605  0.17195326 0.45158623]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.16424616426311453\n",
      "iteration out of 8:  1\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.06047584 0.32014208 0.07011395 0.1264605  0.17195326 0.45158623\n",
      " 0.35011529 0.2844497  0.01525046]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.7701776041048883\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.06047584 0.32014208 0.07011395 0.1264605  0.17195326 0.45158623\n",
      " 0.35011529 0.2844497  0.01525046]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.2032399535161512\n",
      "iteration out of 8:  1\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.04469306 0.23659251 0.05181585 0.09345728 0.12707749 0.33373282\n",
      " 0.25874341 0.210215   0.01127045 0.28502526 0.15341873 0.31155601]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.16322982860974383\n",
      "iteration out of 8:  1\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.04469306 0.23659251 0.05181585 0.09345728 0.12707749 0.33373282\n",
      " 0.25874341 0.210215   0.01127045 0.28502526 0.15341873 0.31155601\n",
      " 0.09883014 0.02209701 0.33665053]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1671136249710102\n",
      "iteration out of 8:  1\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.07858191 0.41599053 0.09110561 0.16432195]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.009209917824733e-12\n",
      "iteration out of 8:  1\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.03605176 0.19084787 0.04179737 0.07538752 0.10250734 0.26920632\n",
      " 0.20871594 0.1695704 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.746467046840385\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.03605176 0.19084787 0.04179737 0.07538752 0.10250734 0.26920632\n",
      " 0.20871594 0.1695704 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07662601811858342\n",
      "iteration out of 8:  1\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.03605176 0.19084787 0.04179737 0.07538752 0.10250734 0.26920632\n",
      " 0.20871594 0.1695704  0.00909133 0.22991626 0.12375556 0.25131734]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08580861465210614\n",
      "iteration out of 8:  1\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.03605176 0.19084787 0.04179737 0.07538752 0.10250734 0.26920632\n",
      " 0.20871594 0.1695704  0.00909133 0.22991626 0.12375556 0.25131734\n",
      " 0.07972155 0.0178246  0.2715599  0.0692583 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11411268140341355\n",
      "iteration out of 8:  1\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.03605176 0.19084787 0.04179737 0.07538752 0.10250734 0.26920632\n",
      " 0.20871594 0.1695704  0.00909133 0.22991626 0.12375556 0.25131734\n",
      " 0.07972155 0.0178246  0.2715599  0.0692583  0.12690136 0.0990472\n",
      " 0.02402186 0.26422012]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13137052700006951\n",
      "iteration out of 8:  1\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.06054481 0.32050719 0.07019391 0.12660473 0.17214937]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 9.76550820726668e-09\n",
      "iteration out of 8:  1\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.03050063 0.16146177 0.03536156 0.06377961 0.08672361 0.22775486\n",
      " 0.17657858 0.14346053 0.00769148 0.19451455]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08489828157837924\n",
      "iteration out of 8:  1\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.03050063 0.16146177 0.03536156 0.06377961 0.08672361 0.22775486\n",
      " 0.17657858 0.14346053 0.00769148 0.19451455 0.1047001  0.21262037\n",
      " 0.0674463  0.01508003 0.22974604]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08267528141860468\n",
      "iteration out of 8:  1\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.03050063 0.16146177 0.03536156 0.06377961 0.08672361 0.22775486\n",
      " 0.17657858 0.14346053 0.00769148 0.19451455 0.1047001  0.21262037\n",
      " 0.0674463  0.01508003 0.22974604 0.05859415 0.10736153 0.08379626\n",
      " 0.02032306 0.22353642]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08516881390981623\n",
      "iteration out of 8:  1\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.02392963 0.12667676 0.02774333 0.05003905 0.06804005 0.17868779\n",
      " 0.13853684 0.11255367 0.00603444 0.15260871 0.08214372 0.16681385\n",
      " 0.0529158  0.01183122 0.18025    0.04597074 0.08423177 0.06574335\n",
      " 0.0159447  0.17537817 0.17656669 0.20205026 0.08015265 0.1985193\n",
      " 0.09271109]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10563309647367577\n",
      "iteration out of 8:  2\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  2\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.75       0.09414604]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.23500805559503e-16\n",
      "iteration out of 8:  2\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.75       0.09414604 0.66896522]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.2738102794071068e-16\n",
      "iteration out of 8:  2\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.75       0.09414604 0.66896522 0.32386437]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.534399280924134e-16\n",
      "iteration out of 8:  2\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.75       0.09414604 0.66896522 0.32386437 0.32279531]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.1251243440145433e-16\n",
      "iteration out of 8:  2\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.6663539 0.0836461]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.728240013203863e-16\n",
      "iteration out of 8:  2\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.56656249 0.07111948 0.50534746 0.24465254]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.168160111354714\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.56656249 0.07111948 0.50534746 0.24465254]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1088557837150141\n",
      "iteration out of 8:  2\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.56656249 0.07111948 0.50534746 0.24465254 0.24384495 0.41345734]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.3660281226925046\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.56656249 0.07111948 0.50534746 0.24465254 0.24384495 0.41345734]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1307552822806428\n",
      "iteration out of 8:  2\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.56656249 0.07111948 0.50534746 0.24465254 0.24384495 0.41345734\n",
      " 0.26723701 0.27761559]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12551767420635224\n",
      "iteration out of 8:  2\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.51320143 0.06442117 0.45775188 0.22161021 0.22087868 0.37451632\n",
      " 0.24206759 0.25146867 0.31345165 0.43654835]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 0.9977165405091084\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.51320143 0.06442117 0.45775188 0.22161021 0.22087868 0.37451632\n",
      " 0.24206759 0.25146867 0.31345165 0.43654835]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1297056779124739\n",
      "iteration out of 8:  2\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.37175059 0.04666513 0.33158429]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.8004488796824211e-06\n",
      "iteration out of 8:  2\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.37175059 0.04666513 0.33158429 0.16052903 0.15999913 0.27129048]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07825143220967959\n",
      "iteration out of 8:  2\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.37175059 0.04666513 0.33158429 0.16052903 0.15999913 0.27129048\n",
      " 0.17534785 0.18215777 0.22705672]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07770340587769677\n",
      "iteration out of 8:  2\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.29433225 0.03694695 0.26253071 0.1270983  0.12667876 0.2147933\n",
      " 0.13883106 0.14422279 0.17977138 0.25037003 0.33864347 0.1609865 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1015983498007605\n",
      "iteration out of 8:  2\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.29433225 0.03694695 0.26253071 0.1270983  0.12667876 0.2147933\n",
      " 0.13883106 0.14422279 0.17977138 0.25037003 0.33864347 0.1609865\n",
      " 0.15077297 0.0400028  0.0768225 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10821978760166194\n",
      "iteration out of 8:  2\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.30620983 0.03843792 0.27312497 0.13222727]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.6350837819963322e-05\n",
      "iteration out of 8:  2\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.30620983 0.03843792 0.27312497 0.13222727 0.1317908  0.22346115\n",
      " 0.1444335  0.1500428 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09629393979096736\n",
      "iteration out of 8:  2\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.23742308 0.02980326 0.21177038 0.10252384 0.10218541 0.173263\n",
      " 0.11198806 0.1163373  0.14501256 0.20196096 0.27316672 0.12985975]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08077610621988812\n",
      "iteration out of 8:  2\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.23742308 0.02980326 0.21177038 0.10252384 0.10218541 0.173263\n",
      " 0.11198806 0.1163373  0.14501256 0.20196096 0.27316672 0.12985975\n",
      " 0.12162101 0.03226826 0.06196887 0.27229815]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11727170691097016\n",
      "iteration out of 8:  2\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.23316049 0.02926818 0.20796835 0.10068317 0.10035082 0.17015231\n",
      " 0.10997748 0.11424863 0.14240907 0.19833505 0.26826241 0.1275283\n",
      " 0.11943748 0.03168893 0.0608563  0.26740943 0.26346552 0.24628199\n",
      " 0.18053402 0.05971847]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11173384776171022\n",
      "iteration out of 8:  2\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.26044429 0.03269306 0.23230423 0.11246483 0.11209359]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.00011024023812646625\n",
      "iteration out of 8:  2\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.23787921 0.02986051 0.21217722 0.1027208  0.10238172 0.17359587\n",
      " 0.11220321 0.1165608  0.14529116 0.20234896]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.06882252941485084\n",
      "iteration out of 8:  2\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.23787921 0.02986051 0.21217722 0.1027208  0.10238172 0.17359587\n",
      " 0.11220321 0.1165608  0.14529116 0.20234896 0.27369152 0.13010923\n",
      " 0.12185466 0.03233025 0.06208792]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08723932250765015\n",
      "iteration out of 8:  2\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.17187807 0.02157552 0.15330727 0.07422024 0.07397525 0.12543056\n",
      " 0.0810717  0.08422025 0.10497918 0.14620592 0.19775403 0.09400958\n",
      " 0.08804529 0.02336001 0.04486122 0.19712523 0.19421792 0.1815508\n",
      " 0.1330836  0.04402245]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08490987343087407\n",
      "iteration out of 8:  2\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.17187807 0.02157552 0.15330727 0.07422024 0.07397525 0.12543056\n",
      " 0.0810717  0.08422025 0.10497918 0.14620592 0.19775403 0.09400958\n",
      " 0.08804529 0.02336001 0.04486122 0.19712523 0.19421792 0.1815508\n",
      " 0.1330836  0.04402245 0.13111156 0.02864756 0.09443842 0.17991176\n",
      " 0.05320999]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09144376536632995\n",
      "iteration out of 8:  3\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  3\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.75       0.41673786]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.4157814653438918e-16\n",
      "iteration out of 8:  3\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.75       0.41673786 0.21343076]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.3445312308829482e-16\n",
      "iteration out of 8:  3\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.75       0.41673786 0.21343076 0.05861122]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.061671168662005e-16\n",
      "iteration out of 8:  3\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.75       0.41673786 0.21343076 0.05861122 0.33705586]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.040059572340295e-16\n",
      "iteration out of 8:  3\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.48211344 0.26788656]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 6.892132810397807e-17\n",
      "iteration out of 8:  3\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.48211344 0.26788656 0.13719711 0.03767634]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.05945308788195882\n",
      "iteration out of 8:  3\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.48211344 0.26788656 0.13719711 0.03767634 0.21666554 0.2304797 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.048250939248032275\n",
      "iteration out of 8:  3\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.48211344 0.26788656 0.13719711 0.03767634 0.21666554 0.2304797\n",
      " 0.02365302 0.07961577]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07013240167415544\n",
      "iteration out of 8:  3\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.48211344 0.26788656 0.13719711 0.03767634 0.21666554 0.2304797\n",
      " 0.02365302 0.07961577 0.05652249 0.30583462]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13157945397105456\n",
      "iteration out of 8:  3\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.4075589  0.2264603  0.11598081]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.2029255646387603e-16\n",
      "iteration out of 8:  3\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.4075589  0.2264603  0.11598081 0.03185003 0.18316015 0.19483807]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13684981770421487\n",
      "iteration out of 8:  3\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.4075589  0.2264603  0.11598081 0.03185003 0.18316015 0.19483807\n",
      " 0.01999529 0.0673039  0.04778179]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1431830299704183\n",
      "iteration out of 8:  3\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.3476435  0.19316828 0.09893042 0.02716775 0.1562337  0.16619484\n",
      " 0.01705578 0.05740953 0.04075737 0.22053195 0.30095314 0.22851491]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09874189580055542\n",
      "iteration out of 8:  3\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.3476435  0.19316828 0.09893042 0.02716775 0.1562337  0.16619484\n",
      " 0.01705578 0.05740953 0.04075737 0.22053195 0.30095314 0.22851491\n",
      " 0.34824463 0.16533112 0.21733423]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10057464187536877\n",
      "iteration out of 8:  3\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.39095627 0.21723504 0.11125612 0.03055257]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.0001879482281198963\n",
      "iteration out of 8:  3\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.39095627 0.21723504 0.11125612 0.03055257 0.1756988  0.186901\n",
      " 0.01918075 0.06456216]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.052101412040775244\n",
      "iteration out of 8:  3\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.32972519 0.18321196 0.09383133 0.02576746 0.14818107 0.1576288\n",
      " 0.01617668 0.05445051 0.03865665 0.20916525 0.28544135 0.21673675]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.5913550124528744\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.32972519 0.18321196 0.09383133 0.02576746 0.14818107 0.1576288\n",
      " 0.01617668 0.05445051 0.03865665 0.20916525 0.28544135 0.21673675]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.15179226290187284\n",
      "iteration out of 8:  3\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.31403384 0.17449305 0.08936597 0.02454121 0.14112926 0.15012737\n",
      " 0.01540685 0.05185926 0.03681701 0.19921125 0.27185743 0.20642243\n",
      " 0.31457685 0.14934715 0.19632268 0.08975332]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 1.9588608495552187\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.31403384 0.17449305 0.08936597 0.02454121 0.14112926 0.15012737\n",
      " 0.01540685 0.05185926 0.03681701 0.19921125 0.27185743 0.20642243\n",
      " 0.31457685 0.14934715 0.19632268 0.08975332]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12394673532648713\n",
      "iteration out of 8:  3\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.31175635 0.17322757 0.08871786 0.02436323 0.14010574 0.1490386\n",
      " 0.01529511 0.05148316 0.03655    0.1977665  0.26988583 0.20492538\n",
      " 0.31229544 0.14826403 0.19489888 0.0891024  0.30765591 0.21216459\n",
      " 0.13886421 0.09131529]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10398475911741878\n",
      "iteration out of 8:  3\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.31675228 0.17600356 0.09013957 0.02475365 0.14235095]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.0005470409199484003\n",
      "iteration out of 8:  3\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.31675228 0.17600356 0.09013957 0.02475365 0.14235095 0.15142695\n",
      " 0.01554022 0.05230818 0.03713572 0.20093572]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08256381790252929\n",
      "iteration out of 8:  3\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.20686859 0.11494663 0.05886949 0.01616643 0.09296836 0.09889583\n",
      " 0.0101492  0.03416209 0.02425306 0.13122965 0.17908504 0.13597998\n",
      " 0.2072263  0.09838186 0.12932681]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09533342909575071\n",
      "iteration out of 8:  3\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.20686859 0.11494663 0.05886949 0.01616643 0.09296836 0.09889583\n",
      " 0.0101492  0.03416209 0.02425306 0.13122965 0.17908504 0.13597998\n",
      " 0.2072263  0.09838186 0.12932681 0.05912466 0.2041477  0.14078362\n",
      " 0.09214453 0.06059304]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09847157289807972\n",
      "iteration out of 8:  3\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.20686859 0.11494663 0.05886949 0.01616643 0.09296836 0.09889583\n",
      " 0.0101492  0.03416209 0.02425306 0.13122965 0.17908504 0.13597998\n",
      " 0.2072263  0.09838186 0.12932681 0.05912466 0.2041477  0.14078362\n",
      " 0.09214453 0.06059304 0.10661236 0.02352311 0.04747146 0.10009736\n",
      " 0.050777  ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1023533233052731\n",
      "iteration out of 8:  4\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  4\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.75       0.60743254]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.431835814812756e-17\n",
      "iteration out of 8:  4\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.75       0.60743254 0.23829371]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.5489596866837296e-16\n",
      "iteration out of 8:  4\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.75       0.60743254 0.23829371 0.72535523]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.967374278650233e-17\n",
      "iteration out of 8:  4\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.75       0.60743254 0.23829371 0.72535523 0.29956368]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.2929943238697724e-16\n",
      "iteration out of 8:  4\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.41438523 0.33561477]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 6.617099121269449e-17\n",
      "iteration out of 8:  4\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.284830968379001\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12623121919917135\n",
      "iteration out of 8:  4\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 6.606252693882985\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1275205393459713\n",
      "iteration out of 8:  4\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519\n",
      " 0.02266149 0.23307134]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.6331236947194205\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519\n",
      " 0.02266149 0.23307134]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13846633446333198\n",
      "iteration out of 8:  4\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519\n",
      " 0.02266149 0.23307134 0.48252491 0.24054494]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 7.608504683325312\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.41438523 0.33561477 0.13166053 0.40076866 0.16551302 0.49548519\n",
      " 0.02266149 0.23307134 0.48252491 0.24054494]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.16081176749222714\n",
      "iteration out of 8:  4\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.35250407 0.28549659 0.11199934]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.543670863325435e-16\n",
      "iteration out of 8:  4\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.29270919 0.23706812 0.09300101 0.28309086 0.11691339 0.34999575]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10638489557781086\n",
      "iteration out of 8:  4\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.29270919 0.23706812 0.09300101 0.28309086 0.11691339 0.34999575\n",
      " 0.01600739 0.16463455 0.340841  ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.14317880710120057\n",
      "iteration out of 8:  4\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.29270919 0.23706812 0.09300101 0.28309086 0.11691339 0.34999575\n",
      " 0.01600739 0.16463455 0.340841   0.16991367 0.18967966 0.03170747]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1509452609905094\n",
      "iteration out of 8:  4\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.28829404 0.23349225 0.09159821 0.27882079 0.1151499  0.3447165\n",
      " 0.01576594 0.16215124 0.33569985 0.16735073 0.18681858 0.0312292\n",
      " 0.15681173 0.27427518 0.3189131 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13115797150158284\n",
      "iteration out of 8:  4\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 6.752450359254333e-12\n",
      "iteration out of 8:  4\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.0544950271458051\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.0958881234103779\n",
      "iteration out of 8:  4\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656 0.28219389 0.14067732 0.15704226 0.02625169]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1203030160733979\n",
      "iteration out of 8:  4\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656 0.28219389 0.14067732 0.15704226 0.02625169\n",
      " 0.13181809 0.23055948 0.26808272 0.10007044]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.0920100910788437\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656 0.28219389 0.14067732 0.15704226 0.02625169\n",
      " 0.13181809 0.23055948 0.26808272 0.10007044]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11860710465862942\n",
      "iteration out of 8:  4\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656 0.28219389 0.14067732 0.15704226 0.02625169\n",
      " 0.13181809 0.23055948 0.26808272 0.10007044 0.03217754 0.24799437\n",
      " 0.12207346 0.19409225]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.936153766773301\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.24234393 0.19627678 0.07699871 0.23438058 0.09679658 0.28977342\n",
      " 0.01325306 0.13630656 0.28219389 0.14067732 0.15704226 0.02625169\n",
      " 0.13181809 0.23055948 0.26808272 0.10007044 0.03217754 0.24799437\n",
      " 0.12207346 0.19409225]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12210966451564477\n",
      "iteration out of 8:  4\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.2146418  0.17384055 0.06819705 0.20758874 0.08573185]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 4.697099032200978e-10\n",
      "iteration out of 8:  4\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.21080613 0.17073401 0.06697837 0.20387911 0.08419981 0.25206332\n",
      " 0.01152836 0.1185681  0.24547016 0.12237007]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.06560791879154747\n",
      "iteration out of 8:  4\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.21080613 0.17073401 0.06697837 0.20387911 0.08419981 0.25206332\n",
      " 0.01152836 0.1185681  0.24547016 0.12237007 0.13660533 0.02283539\n",
      " 0.11466374 0.20055527 0.23319537]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07764354593716935\n",
      "iteration out of 8:  4\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.21080613 0.17073401 0.06697837 0.20387911 0.08419981 0.25206332\n",
      " 0.01152836 0.1185681  0.24547016 0.12237007 0.13660533 0.02283539\n",
      " 0.11466374 0.20055527 0.23319537 0.08704762 0.02799007 0.21572125\n",
      " 0.10618724 0.16883376]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08997365961806196\n",
      "iteration out of 8:  4\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.21080613 0.17073401 0.06697837 0.20387911 0.08419981 0.25206332\n",
      " 0.01152836 0.1185681  0.24547016 0.12237007 0.13660533 0.02283539\n",
      " 0.11466374 0.20055527 0.23319537 0.08704762 0.02799007 0.21572125\n",
      " 0.10618724 0.16883376 0.00967886 0.08065808 0.01281599 0.10010352\n",
      " 0.0705747 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09754113888502913\n",
      "iteration out of 8:  5\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  5\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.08734513 0.75      ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.465868990766232e-16\n",
      "iteration out of 8:  5\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.08734513 0.75       0.56086245]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.3127096383223123e-16\n",
      "iteration out of 8:  5\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.08734513 0.75       0.56086245 0.27050326]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.096631670857141e-16\n",
      "iteration out of 8:  5\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.08734513 0.75       0.56086245 0.27050326 0.54460037]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.827270148954977e-16\n",
      "iteration out of 8:  5\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.07823399 0.67176601]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.0168516447295483e-14\n",
      "iteration out of 8:  5\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.07823399 0.67176601 0.50235777 0.24228653]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.430893479960819\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.07823399 0.67176601 0.50235777 0.24228653]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.2202604262050109\n",
      "iteration out of 8:  5\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.0564728  0.48491083 0.36262437 0.17489328 0.35211015 0.39788985]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.9999974453864173\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.0564728  0.48491083 0.36262437 0.17489328 0.35211015 0.39788985]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.15162096037045733\n",
      "iteration out of 8:  5\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.0564728  0.48491083 0.36262437 0.17489328 0.35211015 0.39788985\n",
      " 0.3212369  0.20630818]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.13035188925647817\n",
      "iteration out of 8:  5\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.0564728  0.48491083 0.36262437 0.17489328 0.35211015 0.39788985\n",
      " 0.3212369  0.20630818 0.35132686 0.12273477]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1384692113817302\n",
      "iteration out of 8:  5\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.04685202 0.40230078 0.3008472 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.6706817622298918e-06\n",
      "iteration out of 8:  5\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.04579404 0.39321631 0.29405368 0.14182172 0.28552766 0.32265061]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.05864729773729006\n",
      "iteration out of 8:  5\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.04579404 0.39321631 0.29405368 0.14182172 0.28552766 0.32265061\n",
      " 0.26049241 0.16729621 0.28489248]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.080195143481853\n",
      "iteration out of 8:  5\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.04579404 0.39321631 0.29405368 0.14182172 0.28552766 0.32265061\n",
      " 0.26049241 0.16729621 0.28489248 0.09952616 0.1032962  0.00968889]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09746244525236987\n",
      "iteration out of 8:  5\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.04579404 0.39321631 0.29405368 0.14182172 0.28552766 0.32265061\n",
      " 0.26049241 0.16729621 0.28489248 0.09952616 0.1032962  0.00968889\n",
      " 0.03983718 0.12122992 0.25859341]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09927246440691806\n",
      "iteration out of 8:  5\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.03925716 0.33708656 0.25207893 0.12157735]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.9091613667601253e-05\n",
      "iteration out of 8:  5\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.03315312 0.28467341 0.2128835  0.10267345 0.20671099 0.23358658\n",
      " 0.18858644 0.12111599]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07959364501642505\n",
      "iteration out of 8:  5\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.03315312 0.28467341 0.2128835  0.10267345 0.20671099 0.23358658\n",
      " 0.18858644 0.12111599 0.20625115 0.07205309 0.07478246 0.00701438]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10131631056053572\n",
      "iteration out of 8:  5\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.03315312 0.28467341 0.2128835  0.10267345 0.20671099 0.23358658\n",
      " 0.18858644 0.12111599 0.20625115 0.07205309 0.07478246 0.00701438\n",
      " 0.02884058 0.08776578 0.18721163 0.09412584]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11101393461623542\n",
      "iteration out of 8:  5\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.03315312 0.28467341 0.2128835  0.10267345 0.20671099 0.23358658\n",
      " 0.18858644 0.12111599 0.20625115 0.07205309 0.07478246 0.00701438\n",
      " 0.02884058 0.08776578 0.18721163 0.09412584 0.05418796 0.26793755\n",
      " 0.07914345 0.07991089]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11851113237230905\n",
      "iteration out of 8:  5\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.02959767 0.25414411 0.19005318 0.09166241 0.18454263]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.00021701872467513395\n",
      "iteration out of 8:  5\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.02959767 0.25414411 0.19005318 0.09166241 0.18454263 0.20853599\n",
      " 0.16836181 0.10812712 0.1841321  0.06432588]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09399081810835738\n",
      "iteration out of 8:  5\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.02959767 0.25414411 0.19005318 0.09166241 0.18454263 0.20853599\n",
      " 0.16836181 0.10812712 0.1841321  0.06432588 0.06676254 0.00626213\n",
      " 0.02574762 0.07835349 0.16713445]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11565548820663674\n",
      "iteration out of 8:  5\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.02959767 0.25414411 0.19005318 0.09166241 0.18454263 0.20853599\n",
      " 0.16836181 0.10812712 0.1841321  0.06432588 0.06676254 0.00626213\n",
      " 0.02574762 0.07835349 0.16713445 0.08403147 0.04837666 0.23920306\n",
      " 0.07065584 0.07134099]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12382629287995806\n",
      "iteration out of 8:  5\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.02959767 0.25414411 0.19005318 0.09166241 0.18454263 0.20853599\n",
      " 0.16836181 0.10812712 0.1841321  0.06432588 0.06676254 0.00626213\n",
      " 0.02574762 0.07835349 0.16713445 0.08403147 0.04837666 0.23920306\n",
      " 0.07065584 0.07134099 0.24890977 0.03315134 0.19488584 0.00136605\n",
      " 0.22345004]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.132468124031434\n",
      "iteration out of 8:  6\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  6\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.01471298 0.75      ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.617099626792491e-07\n",
      "iteration out of 8:  6\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.01471298 0.75       0.23962795]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.2714767518153432e-06\n",
      "iteration out of 8:  6\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.01471298 0.75       0.23962795 0.2515018 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.2243629938598928e-06\n",
      "iteration out of 8:  6\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.01471298 0.75       0.23962795 0.2515018  0.66626683]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 1.709543791834936e-07\n",
      "iteration out of 8:  6\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.01442991 0.73557009]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.005179429764773\n",
      "iteration out of 8:  6\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.01442991 0.73557009 0.23501754 0.24666294]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.16472612057694017\n",
      "iteration out of 8:  6\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.0117489  0.59890465 0.19135239 0.20083413 0.5320404  0.2179596 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.9998934568665491\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.0117489  0.59890465 0.19135239 0.20083413 0.5320404  0.2179596 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.21926058919829894\n",
      "iteration out of 8:  6\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.00999655 0.50957798 0.16281217 0.17087971 0.45268654 0.18545091\n",
      " 0.49422452 0.25577548]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.887112917825797\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00999655 0.50957798 0.16281217 0.17087971 0.45268654 0.18545091\n",
      " 0.49422452 0.25577548]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.17229219605034052\n",
      "iteration out of 8:  6\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.00999655 0.50957798 0.16281217 0.17087971 0.45268654 0.18545091\n",
      " 0.49422452 0.25577548 0.31334036 0.20414136]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.148209743326066\n",
      "iteration out of 8:  6\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.01098704 0.56006878 0.17894418]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.005027040593797839\n",
      "iteration out of 8:  6\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.00926731 0.47240467 0.15093515 0.15841417 0.41966342 0.17192241]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.8932570034066694\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00926731 0.47240467 0.15093515 0.15841417 0.41966342 0.17192241]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09712821691847878\n",
      "iteration out of 8:  6\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.068889243278541\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.15627412659903223\n",
      "iteration out of 8:  6\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663 0.1439859  0.04527608 0.05720267]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.896475632971027\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663 0.1439859  0.04527608 0.05720267]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.15885391463340437\n",
      "iteration out of 8:  6\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663 0.1439859  0.04527608 0.05720267\n",
      " 0.1793753  0.29508146 0.18547952]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.3951145418816095\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00705081 0.35941783 0.11483541 0.12052564 0.3192909  0.13080307\n",
      " 0.34858866 0.18040471 0.22100663 0.1439859  0.04527608 0.05720267\n",
      " 0.1793753  0.29508146 0.18547952]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12453782903760427\n",
      "iteration out of 8:  6\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.00878672 0.4479064  0.14310786 0.15019902]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.005027045929196547\n",
      "iteration out of 8:  6\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.3244210513327213\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.14944044360005376\n",
      "iteration out of 8:  6\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353 0.16929539 0.11029601 0.03468236 0.04381836]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.7665791409654105\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353 0.16929539 0.11029601 0.03468236 0.04381836]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1473904923885888\n",
      "iteration out of 8:  6\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353 0.16929539 0.11029601 0.03468236 0.04381836\n",
      " 0.13740498 0.22603816 0.14208093 0.18304163]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.41021140469896344\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353 0.16929539 0.11029601 0.03468236 0.04381836\n",
      " 0.13740498 0.22603816 0.14208093 0.18304163]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11877326609080892\n",
      "iteration out of 8:  6\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.00540106 0.27532107 0.08796616 0.09232499 0.24458306 0.1001977\n",
      " 0.26702571 0.13819353 0.16929539 0.11029601 0.03468236 0.04381836\n",
      " 0.13740498 0.22603816 0.14208093 0.18304163 0.10397846 0.14032896\n",
      " 0.05778574 0.1262498 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11053884552977929\n",
      "iteration out of 8:  6\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.00574095 0.29264721 0.09350193 0.09813507 0.25997484]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.006082373644478114\n",
      "iteration out of 8:  6\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.00516019 0.26304281 0.08404321 0.08820765 0.2336756  0.09572927\n",
      " 0.2551174  0.13203063 0.16174547 0.10537723]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07625868024737233\n",
      "iteration out of 8:  6\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.00516019 0.26304281 0.08404321 0.08820765 0.2336756  0.09572927\n",
      " 0.2551174  0.13203063 0.16174547 0.10537723 0.03313566 0.04186423\n",
      " 0.13127725 0.21595773 0.13574467]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10127818651735879\n",
      "iteration out of 8:  6\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.00516019 0.26304281 0.08404321 0.08820765 0.2336756  0.09572927\n",
      " 0.2551174  0.13203063 0.16174547 0.10537723 0.03313566 0.04186423\n",
      " 0.13127725 0.21595773 0.13574467 0.17487868 0.09934143 0.13407083\n",
      " 0.05520872 0.12061955]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10753955726881231\n",
      "iteration out of 8:  6\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.00516019 0.26304281 0.08404321 0.08820765 0.2336756  0.09572927\n",
      " 0.2551174  0.13203063 0.16174547 0.10537723 0.03313566 0.04186423\n",
      " 0.13127725 0.21595773 0.13574467 0.17487868 0.09934143 0.13407083\n",
      " 0.05520872 0.12061955 0.03897435 0.01094874 0.02418905 0.06297166\n",
      " 0.16086018]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12030620425370507\n",
      "iteration out of 8:  7\n",
      "Nin 1\n",
      "Nout 1\n",
      "M_norm [0.75]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.8294704773213825e-17\n",
      "iteration out of 8:  7\n",
      "Nin 1\n",
      "Nout 2\n",
      "M_norm [0.75       0.61567527]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 8.380944256035946e-17\n",
      "iteration out of 8:  7\n",
      "Nin 1\n",
      "Nout 3\n",
      "M_norm [0.24367352 0.20003168 0.75      ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.0742370653636237e-16\n",
      "iteration out of 8:  7\n",
      "Nin 1\n",
      "Nout 4\n",
      "M_norm [0.24367352 0.20003168 0.75       0.72187975]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.804882317026143e-17\n",
      "iteration out of 8:  7\n",
      "Nin 1\n",
      "Nout 5\n",
      "M_norm [0.24367352 0.20003168 0.75       0.72187975 0.55320969]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 3.05144306743466e-16\n",
      "iteration out of 8:  7\n",
      "Nin 2\n",
      "Nout 1\n",
      "M_norm [0.41188415 0.33811585]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 7.572245641320099e-17\n",
      "iteration out of 8:  7\n",
      "Nin 2\n",
      "Nout 2\n",
      "M_norm [0.12416445 0.10192664 0.38216437 0.36783563]\n",
      "R_vec_i has wrong size, initializing all ones\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_mean_loss_ij 0.01391274280103097\n",
      "iteration out of 8:  7\n",
      "Nin 2\n",
      "Nout 3\n",
      "M_norm [0.12416445 0.10192664 0.38216437 0.36783563 0.28188938 0.23387121]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.020370650814821093\n",
      "iteration out of 8:  7\n",
      "Nin 2\n",
      "Nout 4\n",
      "M_norm [0.12416445 0.10192664 0.38216437 0.36783563 0.28188938 0.23387121\n",
      " 0.22565361 0.08681145]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.04979764679529396\n",
      "iteration out of 8:  7\n",
      "Nin 2\n",
      "Nout 5\n",
      "M_norm [0.12416445 0.10192664 0.38216437 0.36783563 0.28188938 0.23387121\n",
      " 0.22565361 0.08681145 0.3175662  0.36974438]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.04820582354201209\n",
      "iteration out of 8:  7\n",
      "Nin 3\n",
      "Nout 1\n",
      "M_norm [0.15309906 0.12567907 0.47122187]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.3706414997520824e-16\n",
      "iteration out of 8:  7\n",
      "Nin 3\n",
      "Nout 2\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 2.8755367494452093\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.12209659348243238\n",
      "iteration out of 8:  7\n",
      "Nin 3\n",
      "Nout 3\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.043591368475398\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.11201517813767056\n",
      "iteration out of 8:  7\n",
      "Nin 3\n",
      "Nout 4\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146 0.31384051 0.25270647 0.17466215]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 4.3452378967853775\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146 0.31384051 0.25270647 0.17466215]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1062148659377574\n",
      "iteration out of 8:  7\n",
      "Nin 3\n",
      "Nout 5\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146 0.31384051 0.25270647 0.17466215\n",
      " 0.15485341 0.28099392 0.29584176]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 5.118548511800971\n",
      "too big loss, decreasing alpha\n",
      "new alpha 0.05\n",
      "M_norm [0.10539128 0.08651574 0.32438265 0.31222035 0.23926883 0.19851082\n",
      " 0.19153569 0.0736859  0.26955146 0.31384051 0.25270647 0.17466215\n",
      " 0.15485341 0.28099392 0.29584176]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10392739321993243\n",
      "iteration out of 8:  7\n",
      "Nin 4\n",
      "Nout 1\n",
      "M_norm [0.09540435 0.07831747 0.29364399 0.2826342 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 9.026664501775447e-12\n",
      "iteration out of 8:  7\n",
      "Nin 4\n",
      "Nout 2\n",
      "M_norm [0.09540435 0.07831747 0.29364399 0.2826342  0.2165956  0.17969983\n",
      " 0.17338567 0.06670339]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.10464748706965446\n",
      "iteration out of 8:  7\n",
      "Nin 4\n",
      "Nout 3\n",
      "M_norm [0.07820196 0.06419602 0.24069694 0.23167233 0.17754117 0.1472981\n",
      " 0.14212244 0.05467608 0.20001136 0.23287451 0.18751211 0.12960202]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.0910218572759378\n",
      "iteration out of 8:  7\n",
      "Nin 4\n",
      "Nout 4\n",
      "M_norm [0.07820196 0.06419602 0.24069694 0.23167233 0.17754117 0.1472981\n",
      " 0.14212244 0.05467608 0.20001136 0.23287451 0.18751211 0.12960202\n",
      " 0.11490362 0.20850183 0.21951916 0.05953878]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.08687413599962346\n",
      "iteration out of 8:  7\n",
      "Nin 4\n",
      "Nout 5\n",
      "M_norm [0.07820196 0.06419602 0.24069694 0.23167233 0.17754117 0.1472981\n",
      " 0.14212244 0.05467608 0.20001136 0.23287451 0.18751211 0.12960202\n",
      " 0.11490362 0.20850183 0.21951916 0.05953878 0.25000756 0.01530921\n",
      " 0.07531086 0.08111206]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.1077707515740431\n",
      "iteration out of 8:  7\n",
      "Nin 5\n",
      "Nout 1\n",
      "M_norm [0.07402606 0.06076802 0.22784398 0.21930128 0.16806066]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 1.487158093111879e-08\n",
      "iteration out of 8:  7\n",
      "Nin 5\n",
      "Nout 2\n",
      "M_norm [0.07402606 0.06076802 0.22784398 0.21930128 0.16806066 0.13943254\n",
      " 0.13453326 0.05175644 0.18933096 0.22043926]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.07199625856335294\n",
      "iteration out of 8:  7\n",
      "Nin 5\n",
      "Nout 3\n",
      "M_norm [0.06819631 0.05598238 0.20990067 0.20203072 0.15482544 0.12845186\n",
      " 0.12393841 0.04768048 0.17442065 0.20307909 0.16352064 0.11301992\n",
      " 0.10020213 0.1818248  0.1914325 ]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.06002968176392286\n",
      "iteration out of 8:  7\n",
      "Nin 5\n",
      "Nout 4\n",
      "M_norm [0.06819631 0.05598238 0.20990067 0.20203072 0.15482544 0.12845186\n",
      " 0.12393841 0.04768048 0.17442065 0.20307909 0.16352064 0.11301992\n",
      " 0.10020213 0.1818248  0.1914325  0.05192102 0.21802002 0.01335046\n",
      " 0.06567511 0.07073408]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.0877219461004833\n",
      "iteration out of 8:  7\n",
      "Nin 5\n",
      "Nout 5\n",
      "M_norm [0.06810888 0.0559106  0.20963156 0.20177171 0.15462695 0.12828717\n",
      " 0.12377951 0.04761935 0.17419703 0.20281873 0.16331099 0.11287503\n",
      " 0.10007367 0.18159169 0.19118708 0.05185445 0.21774051 0.01333334\n",
      " 0.06559091 0.07064339 0.15884284 0.16013335 0.21340936 0.13722577\n",
      " 0.08038867]\n",
      "R_vec_i has wrong size, initializing all ones\n",
      "norm_mean_loss_ij 0.09137486750593941\n"
     ]
    }
   ],
   "source": [
    "window_for_mean = 1000\n",
    "n = 5\n",
    "random_state_M_vec = array([42, 43, 44, 45, 46, 47, 48, 49]) \n",
    "# random_state_M_vec = array([42]) \n",
    "norm_mean_loss = np.zeros([n,n, np.shape(random_state_M_vec)[0]])\n",
    "Nin_vec = np.linspace(1,n,n).astype(np.int32)\n",
    "Nout_vec = np.linspace(1,n,n).astype(np.int32)\n",
    "alpha1: float = 0.2  # for network combine attempt\n",
    "\n",
    "for k, random_state_M in enumerate(random_state_M_vec):\n",
    "    M_values = random_gen_M(random_state_M, 10*10)\n",
    "    for i, Nin in enumerate(Nin_vec):\n",
    "        for j, Nout in enumerate(Nout_vec):\n",
    "            alpha: float = copy.copy(alpha1)\n",
    "            print('iteration out of 8: ', k)\n",
    "            print('Nin', Nin)\n",
    "            print('Nout', Nout)\n",
    "            Variabs, Strctr, State, BigClass = network_build_given_Nin_Nout(Nin, Nout, M_values)\n",
    "            State = train_loop(Variabs, Strctr, State, BigClass)\n",
    "\n",
    "            norm_mean_loss_ij = np.mean(np.mean(np.abs(State.loss_norm_in_t[-window_for_mean:]), axis=1))\n",
    "            print('norm_mean_loss_ij', norm_mean_loss_ij)\n",
    "            \n",
    "            # if loss too big decrease alpha and calculate again\n",
    "            if norm_mean_loss_ij > 0.3:\n",
    "                print('too big loss, decreasing alpha')\n",
    "                alpha = alpha / 4\n",
    "                print('new alpha', alpha)\n",
    "                Variabs, Strctr, State, BigClass = network_build_given_Nin_Nout(Nin, Nout, M_values)\n",
    "                State = train_loop(Variabs, Strctr, State, BigClass)\n",
    "                norm_mean_loss_ij = np.mean(np.mean(np.abs(State.loss_norm_in_t[-window_for_mean:]), axis=1))\n",
    "                print('norm_mean_loss_ij', norm_mean_loss_ij)\n",
    "\n",
    "            norm_mean_loss[i, j, k] = norm_mean_loss_ij\n",
    "            # plot_functions.plot_importants(State, Variabs, State.desired_in_t, Variabs.M, include_network=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b1e88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload the module to reflect any changes made\n",
    "importlib.reload(figure_plots)\n",
    "\n",
    "figure_plots.loss_afo_in_out(norm_mean_loss, cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1890a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.82947048e-17, 3.77181371e-16, 6.12340329e-16, 3.41044972e-16,\n",
       "        3.78903430e-16],\n",
       "       [2.03933552e-16, 3.65339709e-02, 7.56433760e-02, 1.19952213e-01,\n",
       "        1.42935598e-01],\n",
       "       [4.36091370e-16, 1.64246164e-01, 2.03239954e-01, 1.63229829e-01,\n",
       "        1.67113625e-01],\n",
       "       [5.00920992e-12, 7.66260181e-02, 8.58086147e-02, 1.14112681e-01,\n",
       "        1.31370527e-01],\n",
       "       [9.76550821e-09, 8.48982816e-02, 8.26752814e-02, 8.51688139e-02,\n",
       "        1.05633096e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_mean_loss[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a486edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8123498  0.85320847 0.92543266 0.55577651 0.899402  ]\n",
      "[0.7999658  0.79259619 0.90017248 0.56011166 0.98890452]\n",
      "[[-0.012384   -0.06061228 -0.02526018  0.00433515  0.08950252]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'M_values_norm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35428\\771522883.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesired\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_values_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_values_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'M_values_norm' is not defined"
     ]
    }
   ],
   "source": [
    "print(State.output)\n",
    "print(State.desired)\n",
    "print(State.loss)\n",
    "print(np.sum(M_values_norm[:4]))\n",
    "print(M_values_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adfbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_folder_prelim = 'C:/Users/SMR_Admin/OneDrive - huji.ac.il/PhD/Network Simulation repo/Network combine/Network_combine/'\n",
    "save_folder_prelim = 'C:/Users/roiee/OneDrive - huji.ac.il/PhD/Network Simulation repo/Network combine/Network_combine/'\n",
    "\n",
    "np.save(save_folder_prelim + 'loss_mat.npy', norm_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26d4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(norm_mean_loss)\n",
    "# print(np.mean(norm_mean_loss, axis=2))\n",
    "# np.std(norm_mean_loss, axis=2)\n",
    "\n",
    "# norm_mean_loss with markers and no line\n",
    "plt.plot(norm_mean_loss[:, 0], marker='o', linestyle='None')  # 'o' for circle markers, 'None' for no line\n",
    "\n",
    "# Set y-axis to log scale\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend(['Loss at final step'], loc='lower right')\n",
    "\n",
    "# Set y-ticks every 1 unit (for log scale, this will display log-spaced ticks)\n",
    "plt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
